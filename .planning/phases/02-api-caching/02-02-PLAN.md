---
phase: 02-api-caching
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - backend/app/services/__init__.py
  - backend/app/services/cache.py
  - backend/app/services/coalesce.py
  - backend/app/services/menu_service.py
  - backend/app/routers/menus.py
  - backend/app/main.py
autonomous: true

must_haves:
  truths:
    - "GET /api/v2/menus?hall_id=X&date=YYYY-MM-DD&meal=Y returns menu data with stations and items"
    - "A second request for the same hall/date/meal within 30 minutes is served from Redis cache, not by re-running a parser"
    - "Concurrent requests for the same uncached menu result in only one parser invocation (request coalescing)"
    - "Cache TTL varies between 25-35 minutes (jitter prevents synchronized expiration)"
  artifacts:
    - path: "backend/app/services/cache.py"
      provides: "Redis cache get/set with TTL jitter"
      contains: "cache_get"
    - path: "backend/app/services/coalesce.py"
      provides: "In-process request coalescing using asyncio.Future"
      contains: "coalesced_fetch"
    - path: "backend/app/services/menu_service.py"
      provides: "Menu fetch orchestration: cache -> coalesce -> parser -> fallback -> cache write"
      contains: "get_menu"
    - path: "backend/app/routers/menus.py"
      provides: "GET /menus endpoint"
      contains: "router"
  key_links:
    - from: "backend/app/routers/menus.py"
      to: "backend/app/services/menu_service.py"
      via: "function call in route handler"
      pattern: "get_menu"
    - from: "backend/app/services/menu_service.py"
      to: "backend/app/services/cache.py"
      via: "cache_get and cache_set calls"
      pattern: "cache_get|cache_set"
    - from: "backend/app/services/menu_service.py"
      to: "backend/app/services/coalesce.py"
      via: "coalesced_fetch wrapper"
      pattern: "coalesced_fetch"
    - from: "backend/app/services/menu_service.py"
      to: "backend/app/parsers/fallback.py"
      via: "get_menu_with_fallback call"
      pattern: "get_menu_with_fallback"
    - from: "backend/app/main.py"
      to: "backend/app/routers/menus.py"
      via: "app.include_router"
      pattern: "include_router.*menus"
---

<objective>
Build the Redis cache layer, request coalescing for stampede prevention, menu service orchestration, and the menus endpoint.

Purpose: This is the core data-serving pipeline. Menu requests check Redis cache first, coalesce concurrent cache misses to prevent stampedes, run the appropriate parser via the fallback orchestrator, cache the result with TTL jitter, and return structured menu data.
Output: A working /api/v2/menus endpoint backed by Redis caching with stampede prevention.
</objective>

<execution_context>
@/Users/felixpeng/.claude/get-shit-done/workflows/execute-plan.md
@/Users/felixpeng/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-api-caching/02-RESEARCH.md
@.planning/phases/02-api-caching/02-01-SUMMARY.md
@backend/app/main.py
@backend/app/dependencies.py
@backend/app/schemas/menus.py
@backend/app/parsers/__init__.py
@backend/app/parsers/fallback.py
@backend/app/parsers/base.py
@backend/app/parsers/sodexo.py
@backend/app/parsers/bonappetit.py
@backend/app/parsers/pomona.py
@backend/app/models/dining_hall.py
@backend/app/models/enums.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create cache service, coalescing, and menu service</name>
  <files>
    backend/app/services/__init__.py
    backend/app/services/cache.py
    backend/app/services/coalesce.py
    backend/app/services/menu_service.py
  </files>
  <action>
    1. Create `backend/app/services/` directory with empty `__init__.py`

    2. Create `backend/app/services/cache.py`:
       - Constants: BASE_TTL = 1800 (30 min), JITTER_RANGE = 300 (+/- 5 min)
       - `menu_cache_key(hall_id: str, date_str: str, meal: str) -> str`: returns `f"menu:{hall_id}:{date_str}:{meal}"`
       - `async def cache_get(redis_client: Redis, key: str) -> dict | None`: await redis_client.get(key), return json.loads(raw) if not None, else None
       - `async def cache_set(redis_client: Redis, key: str, data: dict) -> None`: compute jittered TTL = BASE_TTL + random.randint(-JITTER_RANGE, JITTER_RANGE), await redis_client.setex(key, ttl, json.dumps(data))
       - Use `json` stdlib for serialization (not Pydantic -- the data is already a dict)

    3. Create `backend/app/services/coalesce.py`:
       - Module-level `_inflight: dict[str, asyncio.Future] = {}`
       - `async def coalesced_fetch(key: str, fetch_fn: Callable[[], Awaitable[T]]) -> T`:
         - If key in _inflight, await and return the existing future
         - Otherwise: create future via loop.create_future(), store in _inflight[key]
         - try: result = await fetch_fn(), future.set_result(result), return result
         - except: future.set_exception(exc), raise
         - finally: _inflight.pop(key, None)
       - Import typing: TypeVar T, Callable, Awaitable
       - Add timeout protection: wrap `await fetch_fn()` with `asyncio.wait_for(..., timeout=30.0)` to prevent indefinite hangs

    4. Create `backend/app/services/menu_service.py`:
       - Parser registry: `PARSER_REGISTRY: dict[str, type[BaseParser]]` mapping vendor_type strings to parser classes:
         - "sodexo" -> SodexoParser
         - "bonappetit" -> BonAppetitParser
         - "pomona" -> PomonaParser
       - Hall config: `HALL_CONFIG: dict[str, dict]` mapping hall_id to {"name": str, "vendor_type": str} for all 7 halls:
         - "hoch" -> {"name": "Hoch-Shanahan", "vendor_type": "sodexo"}
         - "collins" -> {"name": "Collins", "vendor_type": "bonappetit"}
         - "malott" -> {"name": "Malott", "vendor_type": "bonappetit"}
         - "mcconnell" -> {"name": "McConnell", "vendor_type": "bonappetit"}
         - "frank" -> {"name": "Frank", "vendor_type": "pomona"}
         - "frary" -> {"name": "Frary", "vendor_type": "pomona"}
         - "oldenborg" -> {"name": "Oldenborg", "vendor_type": "pomona"}
       - `def get_parser(hall_id: str) -> BaseParser`: Look up hall config, get parser class from PARSER_REGISTRY by vendor_type, instantiate with hall_id and hall_name. Raise ValueError if hall_id unknown.
       - `async def get_menu(hall_id: str, date_str: str, meal: str, session: AsyncSession, redis_client: Redis) -> dict | None`:
         1. Build cache key via menu_cache_key()
         2. Try cache_get(redis_client, cache_key) -- if hit, return cached dict
         3. On cache miss, use coalesced_fetch with the cache key as coalescing key:
            - Inside the fetch_fn: parse target_date from date_str (datetime.date.fromisoformat)
            - Get parser via get_parser(hall_id)
            - Call get_menu_with_fallback(parser, hall_id, target_date, session)
            - Extract the specific meal from the returned ParsedMenu (filter menu.meals by meal name)
            - Convert to dict format matching MenuResponse schema: {"hall_id", "date", "meal", "stations": [...], "is_stale", "fetched_at"}
            - cache_set the result dict
            - Return the dict
         4. Handle case where no menu data found (return None)
       - Import from app.parsers.fallback, app.parsers.sodexo, app.parsers.bonappetit, app.parsers.pomona
       - Import from app.services.cache, app.services.coalesce
  </action>
  <verify>
    - `cd backend && python -c "from app.services.cache import cache_get, cache_set, menu_cache_key; print(menu_cache_key('hoch', '2026-02-08', 'lunch'))"` prints "menu:hoch:2026-02-08:lunch"
    - `python -c "from app.services.coalesce import coalesced_fetch; print('ok')"` succeeds
    - `python -c "from app.services.menu_service import get_parser, get_menu, HALL_CONFIG; p = get_parser('hoch'); print(type(p).__name__)"` prints "SodexoParser"
  </verify>
  <done>
    Cache service provides get/set with jittered TTL. Coalescing deduplicates concurrent requests for same key with 30s timeout. Menu service orchestrates cache check -> coalesced parser run -> cache write for all 7 halls.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create menus router and wire into FastAPI app</name>
  <files>
    backend/app/routers/menus.py
    backend/app/main.py
  </files>
  <action>
    1. Create `backend/app/routers/menus.py`:
       - Create APIRouter with tags=["menus"]
       - GET "/" endpoint (mounted at /api/v2/menus by main.py)
       - Query parameters: hall_id (str, required), date (str, required, format YYYY-MM-DD), meal (str, required)
       - Dependencies: session via Depends(get_session), redis_client via Depends(get_redis)
       - Validate hall_id exists in HALL_CONFIG -- return 404 HTTPException with "Unknown hall_id: {hall_id}" if not
       - Validate date format via datetime.date.fromisoformat -- return 400 HTTPException with "Invalid date format, use YYYY-MM-DD" on ValueError
       - Call get_menu(hall_id, date, meal, session, redis_client)
       - If result is None, return 404 HTTPException with "No menu found for {hall_id} on {date} for {meal}"
       - Return the dict directly (FastAPI serializes it using MenuResponse model via response_model parameter)
       - Set response_model=MenuResponse on the endpoint decorator
       - Import from app.dependencies, app.services.menu_service, app.schemas.menus

    2. Update `backend/app/main.py`:
       - Import menus router: `from app.routers import menus`
       - Add `app.include_router(menus.router, prefix="/api/v2/menus")` after the halls router
       - Remove the placeholder comment for menus router
  </action>
  <verify>
    - `cd backend && python -c "from app.routers.menus import router; print([r.path for r in router.routes])"` shows the route
    - `python -c "from app.main import app; paths = [r.path for r in app.routes]; print('/api/v2/menus/' in paths or '/api/v2/menus' in paths)"` returns True or confirms menus route exists
  </verify>
  <done>
    Menus endpoint accepts hall_id, date, meal query params. Validates inputs. Calls menu service which handles cache -> coalesce -> parser -> fallback chain. Returns MenuResponse. Wired into main app at /api/v2/menus.
  </done>
</task>

</tasks>

<verification>
1. `cd backend && python -c "from app.services.cache import cache_get, cache_set, menu_cache_key, BASE_TTL, JITTER_RANGE; assert BASE_TTL == 1800; assert JITTER_RANGE == 300; print('cache ok')"` passes
2. `python -c "from app.services.menu_service import get_parser; print(type(get_parser('collins')).__name__)"` prints "BonAppetitParser"
3. `python -c "from app.main import app; routes = [r.path for r in app.routes]; print('menus' in str(routes))"` confirms menus route registered
</verification>

<success_criteria>
- Cache service provides get/set with TTL jitter (25-35 min range)
- Request coalescing prevents multiple concurrent parser runs for same key
- Menu service maps hall_id -> parser, orchestrates full cache-aside flow
- Menus endpoint validates inputs, returns 404/400 on bad requests, returns MenuResponse on success
- Menus router mounted in main app at /api/v2/menus
</success_criteria>

<output>
After completion, create `.planning/phases/02-api-caching/02-02-SUMMARY.md`
</output>
