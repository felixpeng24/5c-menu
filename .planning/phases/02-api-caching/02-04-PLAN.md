---
phase: 02-api-caching
plan: 04
type: execute
wave: 3
depends_on: ["02-02", "02-03"]
files_modified:
  - backend/tests/conftest.py
  - backend/tests/test_api_halls.py
  - backend/tests/test_api_menus.py
  - backend/tests/test_api_open_now.py
autonomous: true

must_haves:
  truths:
    - "Integration tests for /api/v2/halls verify correct response shape and status codes"
    - "Integration tests for /api/v2/menus verify cache behavior, input validation, and response shape"
    - "Integration tests for /api/v2/open-now verify time-based filtering and override precedence"
    - "All API tests pass without a real Redis server or real PostgreSQL database"
  artifacts:
    - path: "backend/tests/conftest.py"
      provides: "Shared test fixtures: async client, fake redis, in-memory DB, seeded data"
      contains: "FakeAsyncRedis"
    - path: "backend/tests/test_api_halls.py"
      provides: "Integration tests for halls endpoint"
      contains: "test_list_halls"
    - path: "backend/tests/test_api_menus.py"
      provides: "Integration tests for menus endpoint"
      contains: "test_get_menu"
    - path: "backend/tests/test_api_open_now.py"
      provides: "Integration tests for open-now endpoint"
      contains: "test_open_now"
  key_links:
    - from: "backend/tests/conftest.py"
      to: "backend/app/main.py"
      via: "app import and dependency_overrides"
      pattern: "dependency_overrides"
    - from: "backend/tests/conftest.py"
      to: "backend/app/dependencies.py"
      via: "override get_redis and get_session"
      pattern: "get_redis|get_session"
---

<objective>
Write integration tests for all three API endpoints using fakeredis and an in-memory SQLite database, covering response shapes, status codes, cache behavior, and time-based filtering.

Purpose: Ensure all endpoints work correctly end-to-end without external dependencies (no real Redis, no real PostgreSQL). Validates the full request -> dependency injection -> service -> response pipeline.
Output: Passing test suite covering all three endpoints with expected behaviors.
</objective>

<execution_context>
@/Users/felixpeng/.claude/get-shit-done/workflows/execute-plan.md
@/Users/felixpeng/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-api-caching/02-RESEARCH.md
@.planning/phases/02-api-caching/02-01-SUMMARY.md
@.planning/phases/02-api-caching/02-02-SUMMARY.md
@.planning/phases/02-api-caching/02-03-SUMMARY.md
@backend/app/main.py
@backend/app/dependencies.py
@backend/app/routers/halls.py
@backend/app/routers/menus.py
@backend/app/routers/open_now.py
@backend/app/services/menu_service.py
@backend/app/services/hours_service.py
@backend/app/services/cache.py
@backend/app/models/dining_hall.py
@backend/app/models/dining_hours.py
@backend/app/models/menu.py
@backend/app/schemas/halls.py
@backend/app/schemas/menus.py
@backend/app/schemas/open_now.py
@backend/tests/conftest.py
@backend/pyproject.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Set up test infrastructure with async client, fakeredis, and in-memory DB</name>
  <files>
    backend/tests/conftest.py
  </files>
  <action>
    1. Update `backend/tests/conftest.py` (preserve existing fixtures, ADD new ones):
       - Keep all existing fixtures (sample_menu_item, sample_station, sample_meal, sample_parsed_menu, make_parsed_menu)

    2. Add new imports:
       - `import datetime as _dt`
       - `from httpx import ASGITransport, AsyncClient`
       - `from fakeredis import FakeAsyncRedis`
       - `from sqlmodel import SQLModel`
       - `from sqlalchemy.ext.asyncio import create_async_engine, async_sessionmaker, AsyncSession`
       - `from app.main import app`
       - `from app.dependencies import get_session, get_redis`
       - `from app.models.dining_hall import DiningHall`
       - `from app.models.dining_hours import DiningHours`
       - `from app.models.menu import Menu`

    3. Add `@pytest.fixture` async fixture `test_engine`:
       - Create async engine: `create_async_engine("sqlite+aiosqlite://", echo=False)`
       - NOTE: Add `aiosqlite` to dev dependencies in pyproject.toml
       - Create all tables: `async with engine.begin() as conn: await conn.run_sync(SQLModel.metadata.create_all)`
       - Yield engine
       - Dispose engine after test

    4. Add `@pytest.fixture` async fixture `test_session(test_engine)`:
       - Create async_sessionmaker with test_engine
       - Open session, yield it, close after test

    5. Add `@pytest.fixture` async fixture `fake_redis`:
       - Create `FakeAsyncRedis(decode_responses=True)`
       - Yield it
       - `await r.aclose()` after test

    6. Add `@pytest.fixture` async fixture `seed_halls(test_session)`:
       - Insert all 7 DiningHall rows into the test database:
         - ("hoch", "Hoch-Shanahan", "hmc", "sodexo", "#F5C518")
         - ("collins", "Collins", "cmc", "bonappetit", "#800000")
         - ("malott", "Malott", "scripps", "bonappetit", "#2E4057")
         - ("mcconnell", "McConnell", "pitzer", "bonappetit", "#FF6600")
         - ("frank", "Frank", "pomona", "bonappetit", "#003B5C")
         - ("frary", "Frary", "pomona", "bonappetit", "#003B5C")
         - ("oldenborg", "Oldenborg", "pomona", "bonappetit", "#003B5C")
       - Commit the session
       - NOTE: Use actual school colors from PROJECT.md or reasonable hex values

    7. Add `@pytest.fixture` async fixture `seed_hours(test_session, seed_halls)`:
       - Insert DiningHours rows for at least 2 halls with known start/end times for testing
       - Example: hoch lunch 11:00-13:30 for Monday (day_of_week=1), hoch dinner 17:00-20:00
       - Example: collins lunch 11:30-13:30 for Monday, collins dinner 17:00-19:30
       - Commit

    8. Add `@pytest.fixture` async fixture `seed_menu(test_session, seed_halls)`:
       - Insert a Menu row for hoch/today/lunch with sample stations_json
       - stations_json: [{"name": "Exhibition", "items": [{"name": "Grilled Chicken", "tags": ["gluten-free"]}]}, {"name": "Grill", "items": [{"name": "Hamburger", "tags": []}]}]
       - Commit

    9. Add `@pytest.fixture` async fixture `client(test_session, fake_redis)`:
       - Override dependencies: `app.dependency_overrides[get_session]` = async generator yielding test_session
       - Override: `app.dependency_overrides[get_redis]` = lambda returning fake_redis
       - Create AsyncClient with ASGITransport(app=app), base_url="http://test"
       - Yield the client
       - Clear dependency_overrides after test
       - NOTE: Do NOT use LifespanManager -- dependency overrides bypass the lifespan Redis. The lifespan creates its own Redis client but our overrides replace it for route handlers.
  </action>
  <verify>
    - `cd backend && pip install aiosqlite` succeeds
    - `python -c "from tests.conftest import *; print('conftest ok')"` succeeds (at least no import errors)
  </verify>
  <done>
    Test conftest provides: async client with dependency overrides (fakeredis + in-memory SQLite), seeded dining halls, seeded hours, seeded menu data. All tests can run without external services.
  </done>
</task>

<task type="auto">
  <name>Task 2: Write integration tests for all three endpoints</name>
  <files>
    backend/tests/test_api_halls.py
    backend/tests/test_api_menus.py
    backend/tests/test_api_open_now.py
    backend/pyproject.toml
  </files>
  <action>
    1. Add `aiosqlite` to dev dependencies in `backend/pyproject.toml` and run `pip install -e ".[dev]"`

    2. Create `backend/tests/test_api_halls.py`:
       - `test_list_halls(client, seed_halls)`: GET /api/v2/halls -> 200, response is list of 7 dicts, each has keys id/name/college/vendor_type/color
       - `test_list_halls_empty(client)`: GET /api/v2/halls with no seed data -> 200, empty list
       - `test_hall_response_shape(client, seed_halls)`: Verify first hall has all expected fields and correct types

    3. Create `backend/tests/test_api_menus.py`:
       - `test_get_menu_from_db(client, seed_menu)`: GET /api/v2/menus?hall_id=hoch&date=YYYY-MM-DD&meal=lunch -> 200, response has hall_id/date/meal/stations/is_stale/fetched_at
       - `test_get_menu_invalid_hall(client)`: GET /api/v2/menus?hall_id=nonexistent&date=2026-02-08&meal=lunch -> 404
       - `test_get_menu_invalid_date(client)`: GET /api/v2/menus?hall_id=hoch&date=bad-date&meal=lunch -> 400
       - `test_get_menu_not_found(client, seed_halls)`: GET /api/v2/menus?hall_id=hoch&date=2026-01-01&meal=lunch (no menu data for this date) -> 404
       - `test_menu_cached_on_second_request(client, seed_menu, fake_redis)`: Make same request twice. First request populates cache. Second request should find cache hit (verify by checking redis key exists after first request via fake_redis.get).
       - `test_menu_response_shape(client, seed_menu)`: Verify response matches MenuResponse schema structure: stations is a list, each station has name and items, each item has name and tags
       - NOTE: For the menus tests that need parser invocation (not just DB fallback), you may need to mock the parser's fetch_raw to avoid network calls. Use unittest.mock.patch to mock the parser's fetch_raw method OR seed the Menu table with pre-existing data and rely on the fallback path (simpler, preferred).

    4. Create `backend/tests/test_api_open_now.py`:
       - `test_open_now_returns_open_halls(client, seed_hours)`: Mock the current time to a known time when halls should be open (e.g., Monday 12:00 Pacific). Verify response includes expected halls with current_meal.
       - `test_open_now_returns_empty_when_closed(client, seed_hours)`: Mock time to 03:00 AM when no halls are open. Verify empty list.
       - `test_open_now_override_closes_hall(client, seed_hours, test_session)`: Insert a DiningHoursOverride with start_time=None for a hall that would normally be open. Verify that hall is NOT in response.
       - `test_open_now_response_shape(client, seed_hours)`: Verify each response item has id/name/college/color/current_meal fields.
       - For time mocking: Use unittest.mock.patch on `app.services.hours_service._dt.datetime` or pass `now_override` parameter if the hours_service supports it (Plan 02-03 adds this). The `now_override` approach is cleaner.

    5. Run all tests: `cd backend && python -m pytest tests/ -v`
  </action>
  <verify>
    - `cd backend && python -m pytest tests/test_api_halls.py -v` -- all pass
    - `cd backend && python -m pytest tests/test_api_menus.py -v` -- all pass
    - `cd backend && python -m pytest tests/test_api_open_now.py -v` -- all pass
    - `cd backend && python -m pytest tests/ -v` -- all tests pass (including existing Phase 1 parser tests)
  </verify>
  <done>
    Integration tests cover all three endpoints: halls (list all, empty, response shape), menus (DB fallback, invalid hall 404, invalid date 400, not found 404, cache hit, response shape), open-now (open halls, closed time, override closure, response shape). All tests pass without external services.
  </done>
</task>

</tasks>

<verification>
1. `cd backend && python -m pytest tests/test_api_halls.py tests/test_api_menus.py tests/test_api_open_now.py -v` -- all pass
2. `cd backend && python -m pytest tests/ -v` -- all tests pass (new + existing)
3. Total test count >= 13 new tests across the 3 test files
</verification>

<success_criteria>
- All API integration tests pass without real Redis or PostgreSQL
- Halls tests verify 7 halls returned with correct shape
- Menus tests verify cache behavior, input validation (400/404), and response shape
- Open-now tests verify time-based filtering, override precedence, and response shape
- Existing Phase 1 parser tests still pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/02-api-caching/02-04-SUMMARY.md`
</output>
