---
phase: 01-parsers-data-models
plan: 04
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - backend/app/parsers/pomona.py
  - backend/app/parsers/fallback.py
  - backend/tests/fixtures/pomona/frank_2026-02-07.json
  - backend/tests/fixtures/pomona/frary_2026-02-07.json
  - backend/tests/fixtures/pomona/oldenborg_2026-02-07.json
  - backend/tests/fixtures/pomona/frank_page.html
  - backend/tests/test_pomona_parser.py
  - backend/tests/test_fallback.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Running the Pomona parser returns structured menu data for Frank, Frary, and Oldenborg with station groupings and dietary tags"
    - "Parser dynamically discovers JSON URL from Pomona menu page HTML, not hardcoded"
    - "Oldenborg items split by comma AND slash (other halls comma only)"
    - "Single-item recipe edge case handled (dict normalized to list)"
    - "Fallback orchestrator returns last-known-good data from PostgreSQL when parser fails"
    - "Parser unit tests pass against saved fixtures without network calls"
  artifacts:
    - path: "backend/app/parsers/pomona.py"
      provides: "PomonaParser implementation for 3 halls"
      contains: "class PomonaParser"
      exports: ["PomonaParser"]
    - path: "backend/app/parsers/fallback.py"
      provides: "Fallback orchestrator for all parsers"
      contains: "async def get_menu_with_fallback"
    - path: "backend/tests/test_pomona_parser.py"
      provides: "Pomona parser unit tests"
      contains: "def test_"
    - path: "backend/tests/test_fallback.py"
      provides: "Fallback logic unit tests"
      contains: "def test_"
  key_links:
    - from: "backend/app/parsers/pomona.py"
      to: "backend/app/parsers/base.py"
      via: "inherits BaseParser"
      pattern: "class PomonaParser\\(BaseParser\\)"
    - from: "backend/app/parsers/pomona.py"
      to: "backend/app/parsers/station_filters.py"
      via: "uses POMONA_FILTER and apply_station_filters"
      pattern: "apply_station_filters.*POMONA_FILTER"
    - from: "backend/app/parsers/fallback.py"
      to: "backend/app/models/menu.py"
      via: "queries Menu table for last-known-good data"
      pattern: "select.*Menu"
---

<objective>
Implement the Pomona parser for Frank, Frary, and Oldenborg dining halls with dynamic JSON URL discovery, dietary tags, the Oldenborg split rule, and a fallback orchestrator that returns last-known-good data from PostgreSQL when any parser fails.

Purpose: Completes the parser suite for all 7 dining halls. The fallback orchestrator fulfills PARS-07 (parser failure resilience) which is critical for the system to degrade gracefully.

Output: Working PomonaParser, fallback orchestrator, saved fixtures, passing unit tests.
</objective>

<execution_context>
@/Users/felixpeng/.claude/get-shit-done/workflows/execute-plan.md
@/Users/felixpeng/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-parsers-data-models/01-CONTEXT.md
@.planning/phases/01-parsers-data-models/01-RESEARCH.md
@.planning/phases/01-parsers-data-models/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement PomonaParser with dynamic JSON URL discovery and save fixtures</name>
  <files>
    backend/app/parsers/pomona.py
    backend/tests/fixtures/pomona/frank_2026-02-07.json
    backend/tests/fixtures/pomona/frary_2026-02-07.json
    backend/tests/fixtures/pomona/oldenborg_2026-02-07.json
    backend/tests/fixtures/pomona/frank_page.html
  </files>
  <action>
    1. Create `backend/app/parsers/pomona.py` with `PomonaParser(BaseParser)`:

       **Hall configuration:**
       ```python
       POMONA_HALLS = {
           "frank": {"name": "Frank", "slug": "frank"},
           "frary": {"name": "Frary", "slug": "frary"},
           "oldenborg": {"name": "Oldenborg", "slug": "oldenborg"},
       }
       ```

       **Constructor:**
       - `__init__(self, hall_id: str, hall_name: str)` -- hall_id must be in POMONA_HALLS

       **`async def fetch_raw(self, target_date: date) -> str`:**
       This is a TWO-STEP fetch (different from other parsers):

       a. Step 1: Fetch the Pomona menu page to discover JSON URL
          - URL: `https://www.pomona.edu/administration/dining/menus/{slug}`
          - Use selectolax LexborHTMLParser to find `div#dining-menu-from-json`
          - Extract `data-dining-menu-json-url` attribute value
          - If attribute not found, try fallback URL: `https://my.pomona.edu/eatec/{Name}.json`

       b. Step 2: Fetch the JSON from discovered URL
          - GET the JSON URL
          - Return the raw JSON text

       Both steps use httpx.AsyncClient with User-Agent, follow_redirects=True, timeout=30s.
       If step 1 or step 2 fails, raise with descriptive error.

       **`def parse(self, raw_content: str, target_date: date) -> ParsedMenu`:**

       a. Parse JSON: `json.loads(raw_content)`
          - Navigate to `EatecExchange.menu` array

       b. For each menu entry in the array:
          - `@servedate`: date in YYYYMMDD format. Parse to date object. Filter to target_date.
          - `@mealperiodname`: "Breakfast", "Lunch", "Dinner", or "Closed"
          - `@menubulletin`: if "Closed", skip this entry (hall closed for this meal)

          - `recipes.recipe`: **CRITICAL EDGE CASE** -- can be a dict (single item) OR a list (multiple items). Check with `isinstance(recipes, dict)` and normalize to list. (v1: `isAssoc($menu)`)

          - For each recipe:
            - `@category`: station name
            - `@shortName`: item name
            - `@displayonwebsite`: check if "Y" (skip if "N")
            - `dietaryChoices.dietaryChoice`: array of dicts with `@id` (tag name like "Vegetarian") and `#text` ("Yes"/"No"). Only include tags where #text is "Yes".
            - Normalize dietary tags using DIETARY_TAG_MAP

          - **Oldenborg special handling**: If hall_id == "oldenborg", split item names by BOTH comma AND slash (`re.split(r'[,/]\s*', name)`), creating separate ParsedMenuItem for each part. Other halls split by comma only (`name.split(',')`).
            IMPORTANT: Only split if the item name actually contains commas or slashes. For single-word items, don't split.

          - Apply station merging using POMONA_FILTER.combined (e.g., "grill station" -> "Grill")

       c. For each meal period found for target_date:
          - Apply `apply_station_filters` with `POMONA_FILTER`
          - Build ParsedMeal

       d. Build ParsedMenu. If date not found or all meals are "Closed", return ParsedMenu with empty meals list.

    2. Save fixture files:
       - First fetch the Pomona page for Frank to save: `https://www.pomona.edu/administration/dining/menus/frank`
         Save as `backend/tests/fixtures/pomona/frank_page.html` (for testing JSON URL discovery)
       - Then fetch the JSON URL discovered from that page. Save as `backend/tests/fixtures/pomona/frank_2026-02-07.json`
       - Similarly for Frary and Oldenborg JSON files
       - If live fetches fail (auth redirect, etc.), create synthetic fixtures:
         - For `frank_page.html`: minimal HTML with `<div id="dining-menu-from-json" data-dining-menu-json-url="https://example.com/eatec/Frank.json"></div>`
         - For JSON fixtures: valid EatecExchange structure with at least 2 meal periods, multiple recipes per period, dietaryChoices, and the single-item edge case (one meal period with exactly 1 recipe as a dict not a list)
  </action>
  <verify>
    - `cd /Users/felixpeng/Downloads/repos/5c-menu/backend && python -c "from app.parsers.pomona import PomonaParser; print('PomonaParser imports OK')"` succeeds
    - `ls backend/tests/fixtures/pomona/` shows JSON and HTML fixture files
    - `cd /Users/felixpeng/Downloads/repos/5c-menu/backend && python -c "
from app.parsers.pomona import PomonaParser
from datetime import date

parser = PomonaParser('frank', 'Frank')
with open('tests/fixtures/pomona/frank_2026-02-07.json') as f:
    json_content = f.read()
menu = parser.parse(json_content, date(2026, 2, 7))
print(f'Meals: {len(menu.meals)}')
for meal in menu.meals:
    print(f'  {meal.meal}: {len(meal.stations)} stations')
    for station in meal.stations[:2]:
        print(f'    {station.name}: {len(station.items)} items')
print('Parse test OK')
"` shows meals with stations and items
  </verify>
  <done>
    - PomonaParser inherits BaseParser with two-step fetch (page HTML -> JSON URL -> JSON data)
    - parse() handles EatecExchange JSON structure correctly
    - Single-item recipe edge case handled (dict normalized to list)
    - Oldenborg items split by comma AND slash, other halls by comma only
    - Dietary tags extracted from dietaryChoices where #text is "Yes"
    - Station filter pipeline applied with POMONA_FILTER
    - Fixtures saved for all 3 Pomona halls
  </done>
</task>

<task type="auto">
  <name>Task 2: Fallback orchestrator and all unit tests</name>
  <files>
    backend/app/parsers/fallback.py
    backend/tests/test_pomona_parser.py
    backend/tests/test_fallback.py
  </files>
  <action>
    1. Create `backend/app/parsers/fallback.py`:

       **`async def persist_menu(session: AsyncSession, hall_id: str, target_date: date, menu: ParsedMenu) -> None`:**
       - For each meal in menu.meals:
         - Upsert into Menu table (match on hall_id + date + meal)
         - Set stations_json to JSON serialization of stations (list of dicts with name and items)
         - Set fetched_at to utcnow
         - Set is_valid to True
       - Commit the session

       **`async def load_latest_menu(session: AsyncSession, hall_id: str, target_date: date) -> tuple[ParsedMenu | None, datetime | None]`:**
       - Query Menu table for most recent valid entries matching hall_id and target_date
       - Group by meal period
       - Reconstruct ParsedMenu from stored JSONB data
       - Return (menu, fetched_at) or (None, None) if nothing stored

       **`async def get_menu_with_fallback(parser: BaseParser, hall_id: str, target_date: date, session: AsyncSession) -> tuple[ParsedMenu | None, bool, datetime | None]`:**
       - Returns (menu, is_stale, fetched_at)
       - is_stale=False means fresh data, is_stale=True means fallback
       - Try:
         - Call parser.fetch_and_parse(target_date)
         - If successful and valid: persist_menu, return (menu, False, utcnow)
       - Except any Exception:
         - Log warning with hall_id and error
         - Load last-known-good: load_latest_menu(session, hall_id, target_date)
         - If found: return (stored_menu, True, stored_fetched_at)
         - If not found: return (None, True, None)

    2. Create `backend/tests/test_pomona_parser.py`:

       a. **Fixture setup**: Read JSON fixtures for frank, frary, oldenborg. Read frank_page.html.

       b. **Test: parse returns valid menu** (`test_pomona_parse_returns_menu`):
          - Parse Frank JSON fixture
          - Assert ParsedMenu with >= 1 meal

       c. **Test: all 3 halls parse** (`test_pomona_all_halls_parse`):
          - Parse each hall's JSON fixture
          - Assert each produces >= 1 meal

       d. **Test: meals have stations with items** (`test_pomona_meals_have_stations`):
          - Parse Frank fixture
          - Assert stations and items exist

       e. **Test: single-item recipe handling** (`test_pomona_single_item_recipe`):
          - Create synthetic JSON with one meal period where `recipes.recipe` is a dict (not list)
          - Parse and verify it produces 1 item without crashing

       f. **Test: Oldenborg comma-slash splitting** (`test_pomona_oldenborg_splitting`):
          - Create synthetic JSON for "oldenborg" with item name "Pasta/Salad, Bread"
          - Parse and verify it splits into 3 items: "Pasta", "Salad", "Bread"

       g. **Test: non-Oldenborg comma-only splitting** (`test_pomona_frank_comma_only_split`):
          - Create synthetic JSON for "frank" with item name "Pasta/Salad, Bread"
          - Parse and verify comma split only: "Pasta/Salad", "Bread"

       h. **Test: station ordering** (`test_pomona_station_ordering`):
          - Parse fixture
          - Verify station ordering follows POMONA_FILTER.ordered

       i. **Test: dietary tags** (`test_pomona_dietary_tags`):
          - Parse fixture (or synthetic JSON with dietaryChoices)
          - Verify tags extracted where #text == "Yes"
          - Verify tags normalized to canonical set

       j. **Test: closed meal periods skipped** (`test_pomona_closed_skipped`):
          - Create synthetic JSON with @mealperiodname "Closed" and @menubulletin "Closed"
          - Parse and verify no meals in output for that date

       k. **Test: JSON URL discovery from HTML** (`test_pomona_json_url_discovery`):
          - Use frank_page.html fixture
          - Use selectolax to find `div#dining-menu-from-json` and extract `data-dining-menu-json-url`
          - Assert a URL is found (or test the discovery logic directly if exposed as a method)

    3. Create `backend/tests/test_fallback.py`:

       a. **Test: persist and load round-trip** (`test_persist_and_load_menu`):
          - Use an in-memory SQLite or mock session
          - Create a ParsedMenu with known data
          - Call persist_menu
          - Call load_latest_menu
          - Assert loaded menu matches original

       b. **Test: fallback on parser failure** (`test_fallback_on_parser_failure`):
          - Mock a parser that raises an exception on fetch_and_parse
          - Pre-populate DB with known menu data
          - Call get_menu_with_fallback
          - Assert returns (stored_menu, True, stored_fetched_at)

       c. **Test: fallback with no stored data** (`test_fallback_no_stored_data`):
          - Mock a parser that raises an exception
          - Empty DB
          - Call get_menu_with_fallback
          - Assert returns (None, True, None)

       d. **Test: fresh parse persists data** (`test_fresh_parse_persists`):
          - Mock a parser that returns valid ParsedMenu
          - Call get_menu_with_fallback
          - Assert returns (menu, False, recent_timestamp)
          - Assert data was persisted (query DB to confirm)

       Note: For fallback tests, if async SQLite testing is too complex to set up, use unittest.mock to mock the session and verify the correct methods are called. The key behavior to verify is the try/except flow and the persist/load logic.
  </action>
  <verify>
    - `cd /Users/felixpeng/Downloads/repos/5c-menu/backend && python -m pytest tests/test_pomona_parser.py -v` -- all tests pass
    - `cd /Users/felixpeng/Downloads/repos/5c-menu/backend && python -m pytest tests/test_fallback.py -v` -- all tests pass
  </verify>
  <done>
    - All Pomona parser tests pass: 3 halls, single-item edge case, Oldenborg splitting, station ordering, dietary tags, closed meals, JSON URL discovery
    - Fallback orchestrator tests pass: persist/load round-trip, fallback on failure, fallback with no data, fresh parse persistence
    - Zero network calls in all tests
  </done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_pomona_parser.py tests/test_fallback.py -v` -- all tests pass
- PomonaParser handles all 3 Pomona halls correctly
- Single-item recipe edge case does not crash
- Oldenborg items split by comma AND slash
- Fallback orchestrator correctly falls back to DB data on parser failure
- All parsers from all plans can be imported: `python -c "from app.parsers.sodexo import SodexoParser; from app.parsers.bonappetit import BonAppetitParser; from app.parsers.pomona import PomonaParser; from app.parsers.fallback import get_menu_with_fallback; print('All parsers OK')"`
</verification>

<success_criteria>
- PomonaParser.parse() handles EatecExchange JSON with all edge cases
- Dynamic JSON URL discovery from page HTML (not hardcoded)
- Oldenborg comma+slash splitting works, other halls comma-only
- Single-item recipe (dict not list) handled gracefully
- Dietary tags extracted from dietaryChoices and normalized
- Fallback orchestrator: fresh data persisted, stale data returned on failure, None returned when no stored data
- All tests pass without network calls
- All 7 dining halls covered across the 3 parser implementations
</success_criteria>

<output>
After completion, create `.planning/phases/01-parsers-data-models/01-04-SUMMARY.md`
</output>
