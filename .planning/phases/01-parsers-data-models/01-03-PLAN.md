---
phase: 01-parsers-data-models
plan: 03
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - backend/app/parsers/bonappetit.py
  - backend/tests/fixtures/bonappetit/collins_2026-02-07.html
  - backend/tests/fixtures/bonappetit/malott_2026-02-07.html
  - backend/tests/fixtures/bonappetit/mcconnell_2026-02-07.html
  - backend/tests/test_bonappetit_parser.py
autonomous: true
user_setup: []

must_haves:
  truths:
    - "Running the Bon Appetit parser returns structured menu data for Collins, Malott, and McConnell with station groupings and dietary tags"
    - "Parser extracts Bamco.menu_items and Bamco.dayparts from inline JavaScript via regex"
    - "Items with special=false are filtered out (only items being served today appear)"
    - "Dietary tags extracted from cor_icon dictionary values"
    - "Station filtering matches v1 BAMCO rules"
    - "Parser unit tests pass against saved HTML fixtures without network calls"
  artifacts:
    - path: "backend/app/parsers/bonappetit.py"
      provides: "BonAppetitParser implementation for 3 halls"
      contains: "class BonAppetitParser"
      exports: ["BonAppetitParser"]
    - path: "backend/tests/test_bonappetit_parser.py"
      provides: "Bon Appetit parser unit tests"
      contains: "def test_"
    - path: "backend/tests/fixtures/bonappetit/collins_2026-02-07.html"
      provides: "Collins fixture for offline testing"
  key_links:
    - from: "backend/app/parsers/bonappetit.py"
      to: "backend/app/parsers/base.py"
      via: "inherits BaseParser"
      pattern: "class BonAppetitParser\\(BaseParser\\)"
    - from: "backend/app/parsers/bonappetit.py"
      to: "backend/app/parsers/station_filters.py"
      via: "uses BONAPPETIT_FILTER and apply_station_filters"
      pattern: "apply_station_filters.*BONAPPETIT_FILTER"
---

<objective>
Implement the Bon Appetit parser for Collins (CMC), Malott (Scripps), and McConnell (Pitzer) dining halls with regex extraction of Bamco.menu_items and Bamco.dayparts from inline JavaScript, station filtering, dietary tags, and fixture-based unit tests.

Purpose: BAMCO is the most complex vendor (3 halls, JS object extraction, special field filtering, cor_icon dietary tags). This is the highest-risk parser due to the non-standard data source.

Output: Working BonAppetitParser, saved HTML fixtures for all 3 halls, passing unit tests.
</objective>

<execution_context>
@/Users/felixpeng/.claude/get-shit-done/workflows/execute-plan.md
@/Users/felixpeng/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-parsers-data-models/01-CONTEXT.md
@.planning/phases/01-parsers-data-models/01-RESEARCH.md
@.planning/phases/01-parsers-data-models/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement BonAppetitParser and save fixtures</name>
  <files>
    backend/app/parsers/bonappetit.py
    backend/tests/fixtures/bonappetit/collins_2026-02-07.html
    backend/tests/fixtures/bonappetit/malott_2026-02-07.html
    backend/tests/fixtures/bonappetit/mcconnell_2026-02-07.html
  </files>
  <action>
    1. Create `backend/app/parsers/bonappetit.py` with `BonAppetitParser(BaseParser)`:

       **Hall configuration (class-level or module-level dict):**
       ```python
       BAMCO_HALLS = {
           "collins": {
               "name": "Collins",
               "url": "https://collins-cmc.cafebonappetit.com/cafe/collins/{date}",
           },
           "malott": {
               "name": "Malott",
               "url": "https://scripps.cafebonappetit.com/cafe/malott-dining-commons/{date}",
           },
           "mcconnell": {
               "name": "McConnell",
               "url": "https://pitzer.cafebonappetit.com/cafe/mcconnell-bistro/{date}",
           },
       }
       ```

       **Constructor:**
       - `__init__(self, hall_id: str, hall_name: str)` -- hall_id must be in BAMCO_HALLS
       - Store the URL template for this hall

       **`build_url(self, target_date: date) -> str`:**
       - Format date as YYYY-MM-DD
       - Substitute into URL template

       **`async def fetch_raw(self, target_date: date) -> str`:**
       - Use httpx.AsyncClient with User-Agent header, follow_redirects=True, timeout=30s
       - GET the built URL
       - Return response.text

       **`def parse(self, raw_content: str, target_date: date) -> ParsedMenu`:**
       This is the core complexity. Steps:

       a. **Extract Bamco.menu_items** from page HTML:
          - Regex: `r'Bamco\.menu_items\s*=\s*(\{[^;]+\});'`
          - json.loads the captured group
          - If not found, raise ValueError("Could not find Bamco.menu_items in page")

       b. **Extract Bamco.dayparts** from page HTML:
          - Regex: `r"Bamco\.dayparts\[\'(\d+)\'\]\s*=\s*(\{[^;]+\});"`
          - Use re.finditer to get ALL daypart assignments
          - json.loads each captured group
          - Build dict: daypart_id -> daypart_data
          - If no dayparts found, raise ValueError("Could not find Bamco.dayparts in page")

       c. **Build meals from dayparts:**
          For each daypart:
          - `label`: meal name (e.g., "Breakfast", "Lunch", "Dinner", "Late Night")
          - `stations`: array of station objects, each with:
            - `label`: station display name (may contain HTML like `<strong>@herbivore</strong>`)
            - `items`: array of item ID strings

          For each station in the daypart:
          - Clean station label: strip HTML tags (`re.sub(r'<[^>]+>', '', label)`), strip leading "@" and whitespace
          - For each item ID in the station's items list:
            - Look up in menu_items dict
            - **CRITICAL: Filter by `special` field** -- only include items where `special` is truthy (v1: `if(!$menuItem["special"]) { continue; }`)
            - Extract item label (the food name)
            - Extract dietary tags from `cor_icon` dict: values are tag names like "Vegan", "Vegetarian", etc. Normalize using DIETARY_TAG_MAP (lowercase before lookup)
            - Skip items with empty labels
            - Deduplicate items within a station (same label = keep first occurrence)
          - Build ParsedStation

       d. **Apply station filtering:**
          - Apply `apply_station_filters` with `BONAPPETIT_FILTER`

       e. **Special BAMCO behaviors to replicate from v1:**
          - "Collins Late Night Snack" station from dinner daypart: also add to "Late Night" meal (if late night daypart exists)
          - "breakfast" station should be hidden when the meal is NOT breakfast (v1 has this logic)
          - Station "grill special" is renamed to "grill" via COMBINED_STATIONS
          - Duplicate items within same station (same label): merge to single entry
          - Station label cleaning: strip HTML tags, strip leading "@" symbol

       f. Build ParsedMenu with all meals

    2. Save fixture files for all 3 halls:
       - Fetch Collins: `https://collins-cmc.cafebonappetit.com/cafe/collins/2026-02-07`
       - Fetch Malott: `https://scripps.cafebonappetit.com/cafe/malott-dining-commons/2026-02-07`
       - Fetch McConnell: `https://pitzer.cafebonappetit.com/cafe/mcconnell-bistro/2026-02-07`
       - Use httpx with User-Agent header
       - Save to `backend/tests/fixtures/bonappetit/{hall}_{date}.html`
       - If any live fetch fails, create a synthetic fixture that contains valid `Bamco.menu_items = {...};` and `Bamco.dayparts['ID'] = {...};` JavaScript objects matching the expected structure. Include items with special:true and special:false, cor_icon dietary tags, and multiple dayparts (breakfast, lunch, dinner).
  </action>
  <verify>
    - `cd /Users/felixpeng/Downloads/repos/5c-menu/backend && python -c "from app.parsers.bonappetit import BonAppetitParser; print('BonAppetitParser imports OK')"` succeeds
    - `ls backend/tests/fixtures/bonappetit/` shows fixture files
    - `cd /Users/felixpeng/Downloads/repos/5c-menu/backend && python -c "
from app.parsers.bonappetit import BonAppetitParser
from datetime import date

parser = BonAppetitParser('collins', 'Collins')
with open('tests/fixtures/bonappetit/collins_2026-02-07.html') as f:
    html = f.read()
menu = parser.parse(html, date(2026, 2, 7))
print(f'Meals: {len(menu.meals)}')
for meal in menu.meals:
    print(f'  {meal.meal}: {len(meal.stations)} stations')
    for station in meal.stations[:2]:
        print(f'    {station.name}: {len(station.items)} items')
        if station.items:
            item = station.items[0]
            print(f'      First: {item.name}, tags: {item.tags}')
print('Parse test OK')
"` shows meals with stations and items
  </verify>
  <done>
    - BonAppetitParser inherits BaseParser with fetch_raw and parse implemented
    - Regex extraction of Bamco.menu_items and Bamco.dayparts works
    - Items filtered by special field (only special=true included)
    - Dietary tags extracted from cor_icon values
    - Station filter pipeline applied with BONAPPETIT_FILTER
    - HTML station labels cleaned (no HTML tags, no "@" prefix)
    - Fixture files saved for all 3 BAMCO halls
  </done>
</task>

<task type="auto">
  <name>Task 2: Bon Appetit parser unit tests</name>
  <files>
    backend/tests/test_bonappetit_parser.py
  </files>
  <action>
    Create `backend/tests/test_bonappetit_parser.py` with pytest tests:

    1. **Fixture setup:**
       - `@pytest.fixture` for each hall's HTML fixture (collins, malott, mcconnell)
       - `@pytest.fixture` for parser instances

    2. **Test: regex extraction works** (`test_bamco_regex_extraction`):
       - Parse Collins fixture
       - Assert result is a ParsedMenu with at least 1 meal
       - Assert menu.hall_id == "collins"

    3. **Test: all 3 halls parse successfully** (`test_bamco_all_halls_parse`):
       - Parse each hall's fixture with corresponding parser
       - Assert each returns a ParsedMenu with >= 1 meal

    4. **Test: meals have stations with items** (`test_bamco_meals_have_stations`):
       - Parse Collins fixture
       - For each meal, assert stations exist
       - For first station, assert items exist with non-empty names

    5. **Test: special field filtering** (`test_bamco_special_filtering`):
       - This is critical: verify that items where special=false are NOT in the output
       - Create a small synthetic HTML with Bamco.menu_items containing 2 items (one special:true, one special:false) and a daypart referencing both
       - Parse it and verify only the special:true item appears

    6. **Test: hidden stations filtered** (`test_bamco_hidden_stations_filtered`):
       - Parse fixture
       - Collect all station names (lowercase)
       - Assert none of BONAPPETIT_FILTER.hidden appear

    7. **Test: station ordering** (`test_bamco_station_ordering`):
       - Parse fixture
       - For any meal with 2+ stations, verify stations in ORDERED_STATIONS appear in correct relative order

    8. **Test: dietary tags from cor_icon** (`test_bamco_dietary_tags`):
       - Parse fixture
       - Collect all tags from all items
       - Assert some items have tags
       - Assert all tags are from canonical set

    9. **Test: HTML stripped from station labels** (`test_bamco_station_label_cleaning`):
       - Create synthetic HTML with station label `<strong>@herbivore</strong>`
       - Parse and verify station name is "herbivore" (no HTML, no @)

    10. **Test: duplicate items deduplicated** (`test_bamco_duplicate_items`):
        - Create synthetic HTML with same item appearing twice in one station
        - Parse and verify only one instance appears

    11. **Test: truncation applied** (`test_bamco_truncation`):
        - Parse fixture
        - If "grill" station exists, assert <= 3 items
        - If "breakfast" station exists in breakfast meal, assert <= 12 items

    Ensure all tests use fixture files or synthetic HTML -- NO network calls.
  </action>
  <verify>
    `cd /Users/felixpeng/Downloads/repos/5c-menu/backend && python -m pytest tests/test_bonappetit_parser.py -v` -- all tests pass
  </verify>
  <done>
    - All Bon Appetit parser tests pass against fixture HTML
    - Tests cover: regex extraction, special field filtering, station filtering, dietary tags, label cleaning, deduplication, all 3 halls
    - Zero network calls in tests
  </done>
</task>

</tasks>

<verification>
- `python -m pytest tests/test_bonappetit_parser.py -v` -- all tests pass
- BonAppetitParser can parse all 3 hall fixtures and produce structured meals
- Special=false items are filtered out
- Dietary tags from cor_icon are normalized
- Station filtering matches v1 BAMCO rules
</verification>

<success_criteria>
- BonAppetitParser.parse() extracts Bamco.menu_items and Bamco.dayparts via regex
- Only items with special=true appear in output
- Dietary tags extracted from cor_icon and normalized (Vegan, Vegetarian, gluten-free, etc.)
- Hidden stations removed, stations ordered, truncation applied per BONAPPETIT_FILTER
- HTML stripped from station labels, "@" prefix removed
- Duplicate items within stations deduplicated
- All 3 halls (Collins, Malott, McConnell) parse successfully from fixtures
- All tests pass without network calls
</success_criteria>

<output>
After completion, create `.planning/phases/01-parsers-data-models/01-03-SUMMARY.md`
</output>
